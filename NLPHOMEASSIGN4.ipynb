{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI4q3dquDvUz",
        "outputId": "8ff9a8d4-8c8a-41e2-c22f-ce99d0984a0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Tokens: ['NLP', 'techniques', 'are', 'used', 'in', 'virtual', 'assistants', 'like', 'Alexa', 'and', 'Siri', '.']\n",
            "Tokens Without Stopwords: ['NLP', 'techniques', 'used', 'virtual', 'assistants', 'like', 'Alexa', 'Siri']\n",
            "Stemmed Words: ['nlp', 'techniqu', 'use', 'virtual', 'assist', 'like', 'alexa', 'siri']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "#Q1)NLP Preprocessing Pipeline\n",
        "import nltk\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Download only stopwords\n",
        "nltk.download('stopwords', force=True)\n",
        "\n",
        "def nlp_preprocessing_pipeline(sentence):\n",
        "    # Step 1: Tokenization\n",
        "    tokenizer = TreebankWordTokenizer()\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    print(\"Original Tokens:\", tokens)\n",
        "\n",
        "    # Step 2: Remove Stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words and word.isalpha()]\n",
        "    print(\"Tokens Without Stopwords:\", filtered_tokens)\n",
        "\n",
        "    # Step 3: Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "    print(\"Stemmed Words:\", stemmed_tokens)\n",
        "\n",
        "# Run it\n",
        "sentence = \"NLP techniques are used in virtual assistants like Alexa and Siri.\"\n",
        "nlp_preprocessing_pipeline(sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB6RNmpgD43L",
        "outputId": "b04a1a92-4551-4ce0-b4f8-2561b9ebcc6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: Barack Obama, Label: PERSON, Start: 0, End: 12\n",
            "Text: 44th, Label: ORDINAL, Start: 27, End: 31\n",
            "Text: the United States, Label: GPE, Start: 45, End: 62\n",
            "Text: the Nobel Peace Prize, Label: WORK_OF_ART, Start: 71, End: 92\n",
            "Text: 2009, Label: DATE, Start: 96, End: 100\n"
          ]
        }
      ],
      "source": [
        "#Q2) Named Entity Recognition with SpaCy\n",
        "\n",
        "import spacy\n",
        "\n",
        "# Load the English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Input sentence\n",
        "text = \"Barack Obama served as the 44th President of the United States and won the Nobel Peace Prize in 2009.\"\n",
        "\n",
        "# Process the sentence\n",
        "doc = nlp(text)\n",
        "\n",
        "# Print named entities\n",
        "for ent in doc.ents:\n",
        "    print(f\"Text: {ent.text}, Label: {ent.label_}, Start: {ent.start_char}, End: {ent.end_char}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w74fj5IqFVDj",
        "outputId": "3b0c5aed-bf09-4ce7-bb5e-26a2329115ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attention Weights:\n",
            " [[0.73105858 0.26894142]\n",
            " [0.26894142 0.73105858]]\n",
            "\n",
            "Final Output:\n",
            " [[2.07576569 3.07576569 4.07576569 5.07576569]\n",
            " [3.92423431 4.92423431 5.92423431 6.92423431]]\n"
          ]
        }
      ],
      "source": [
        "#Q3) Scaled Dot-Product Attention\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return e_x / e_x.sum(axis=-1, keepdims=True)\n",
        "\n",
        "def scaled_dot_product_attention(Q, K, V):\n",
        "    d_k = Q.shape[-1]\n",
        "\n",
        "    # Step 1: QK\u1d40\n",
        "    scores = np.dot(Q, K.T)\n",
        "\n",
        "    # Step 2: Scale\n",
        "    scaled_scores = scores / np.sqrt(d_k)\n",
        "\n",
        "    # Step 3: Softmax\n",
        "    attention_weights = softmax(scaled_scores)\n",
        "\n",
        "    # Step 4: Multiply by V\n",
        "    output = np.dot(attention_weights, V)\n",
        "\n",
        "    return attention_weights, output\n",
        "\n",
        "# Test inputs\n",
        "Q = np.array([[1, 0, 1, 0], [0, 1, 0, 1]])\n",
        "K = np.array([[1, 0, 1, 0], [0, 1, 0, 1]])\n",
        "V = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
        "\n",
        "# Run attention\n",
        "attention_weights, output = scaled_dot_product_attention(Q, K, V)\n",
        "\n",
        "# Print results\n",
        "print(\"Attention Weights:\\n\", attention_weights)\n",
        "print(\"\\nFinal Output:\\n\", output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386,
          "referenced_widgets": [
            "598a221f4600418d8bf6ab7a66e47f7f",
            "6ce50963fdd24dc7acdd2bd28eb8e783",
            "df4ac40df28e49f3b7409e2ac58d6172",
            "e1a9cc81226642229244d98a2c023d5a",
            "d1e22ec5ff2642678ff2ef522174cf79",
            "72a05b2102ca409aacb74748ae5dd54e",
            "02a8eccaa7364f05bb708e38295ec618",
            "a002a1ac562046c3b81f5074b3ee6fc6",
            "5e6f988fef004b74b42f1352729fc601",
            "3c3858e009124130843816598e8506a0",
            "b48fb70fcfc04e63932528a7136aef28",
            "b2345fb094874d23b29b9be839d595a7",
            "4bee959f1c0a4179bf1587ed963080d5",
            "84c974738148426085649da60ab9b118",
            "3d2d74d3b0254cfa8ea7006efcd4c16f",
            "a0f55fcbe51946648bc31ba03a1c579a",
            "008383272b0943988cddbab00ab1002a",
            "b240b3fd92dd47daa9247b13963260ac",
            "faadca904f914b56a9e1fd93cdca19ae",
            "0f736576b1e1451d941243625772de39",
            "15edb3ef37ef497b8d545cf8378a578e",
            "6f12aa2f70f746a4b2d8ec02af61f36f",
            "b63ffc8ebaf849dc9bfc4bff313d775f",
            "b5709f03c6334f9792d4ecf8782c74f8",
            "8dd1f4b9ea504b13b31309480d04afb0",
            "bcf8fe1bd02e4acbb16e9b0ef02a0e3b",
            "25e957488cdc4116bd2b810d261a9ecd",
            "82c9afae798d4d06a3bbf63219dd36c7",
            "d9a01471450b4dbfa58d4e805ec3c190",
            "c5617631273346f0946475f7b100a6e3",
            "14a49cd592d44cc995685acc896a817a",
            "9d7605b0fa3d4a958bfee97d2ac7498f",
            "cc4747e57d7a409f9c5f5f9c9921eb6a",
            "33e1e36ec89642d7afa2d5e1b4ca1113",
            "12803b7f4f304b3c872ee4e1d459f995",
            "86a807ed62f84efe8247fe04368f4df6",
            "c35244dd7a3d40aa9f212f1ac9d4d2e1",
            "8a4661438bb74336bf00f5e8dfa49048",
            "28a3135d2e2440c58a37308875b941c6",
            "383f7926c7814ac8a95d0de3f289551a",
            "4832bab13124442fbb5b8c9e49bf8ae8",
            "f94932d7a0a740e78d7db9eb8bb50438",
            "9deb3e3515074d0d8904b5641d6b9471",
            "0850db4b410045408d94405e26ab950b"
          ]
        },
        "id": "ENwKcqfTFt8v",
        "outputId": "a8f7b49c-f12c-4b58-df09-9cfab6e33667"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "598a221f4600418d8bf6ab7a66e47f7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2345fb094874d23b29b9be839d595a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b63ffc8ebaf849dc9bfc4bff313d775f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33e1e36ec89642d7afa2d5e1b4ca1113",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment: POSITIVE\n",
            "Confidence Score: 0.9998\n"
          ]
        }
      ],
      "source": [
        "#Q4) Sentiment Analysis using HuggingFace Transformers\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load sentiment analysis pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Input sentence\n",
        "text = \"Despite the high price, the performance of the new MacBook is outstanding.\"\n",
        "\n",
        "# Analyze sentiment\n",
        "result = classifier(text)[0]\n",
        "\n",
        "# Print result\n",
        "print(f\"Sentiment: {result['label']}\")\n",
        "print(f\"Confidence Score: {round(result['score'], 4)}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}